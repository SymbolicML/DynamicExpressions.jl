<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Eval · DynamicExpressions.jl</title><meta name="title" content="Eval · DynamicExpressions.jl"/><meta property="og:title" content="Eval · DynamicExpressions.jl"/><meta property="twitter:title" content="Eval · DynamicExpressions.jl"/><meta name="description" content="Documentation for DynamicExpressions.jl."/><meta property="og:description" content="Documentation for DynamicExpressions.jl."/><meta property="twitter:description" content="Documentation for DynamicExpressions.jl."/><meta property="og:url" content="https://ai.damtp.cam.ac.uk/dynamicexpressions/stable/eval/"/><meta property="twitter:url" content="https://ai.damtp.cam.ac.uk/dynamicexpressions/stable/eval/"/><link rel="canonical" href="https://ai.damtp.cam.ac.uk/dynamicexpressions/stable/eval/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="DynamicExpressions.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">DynamicExpressions.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../examples/base_operations/">Node and Tree Operations</a></li><li><a class="tocitem" href="../examples/expression/"><code>Expression</code> example</a></li><li><a class="tocitem" href="../examples/structured_expression/"><code>StructuredExpression</code> example</a></li></ul></li><li class="is-active"><a class="tocitem" href>Eval</a><ul class="internal"><li><a class="tocitem" href="#Evaluation"><span>Evaluation</span></a></li><li><a class="tocitem" href="#Derivatives"><span>Derivatives</span></a></li></ul></li><li><a class="tocitem" href="../utils/">Utils</a></li><li><a class="tocitem" href="../api/">API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Eval</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Eval</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/SymbolicML/DynamicExpressions.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/SymbolicML/DynamicExpressions.jl/blob/master/docs/src/eval.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Evaluation-and-Derivatives"><a class="docs-heading-anchor" href="#Evaluation-and-Derivatives">Evaluation &amp; Derivatives</a><a id="Evaluation-and-Derivatives-1"></a><a class="docs-heading-anchor-permalink" href="#Evaluation-and-Derivatives" title="Permalink"></a></h1><h2 id="Evaluation"><a class="docs-heading-anchor" href="#Evaluation">Evaluation</a><a id="Evaluation-1"></a><a class="docs-heading-anchor-permalink" href="#Evaluation" title="Permalink"></a></h2><p>Given an expression tree specified with a <code>Node</code> type, you may evaluate the expression over an array of data with the following command:</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="DynamicExpressions.EvaluateModule.eval_tree_array-Union{Tuple{T}, Tuple{AbstractExpressionNode{T}, AbstractMatrix{T}, OperatorEnum}} where T" href="#DynamicExpressions.EvaluateModule.eval_tree_array-Union{Tuple{T}, Tuple{AbstractExpressionNode{T}, AbstractMatrix{T}, OperatorEnum}} where T"><code>DynamicExpressions.EvaluateModule.eval_tree_array</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">eval_tree_array(
    tree::AbstractExpressionNode{T},
    cX::AbstractMatrix{T},
    operators::OperatorEnum;
    eval_options::Union{EvalOptions,Nothing}=nothing,
) where {T}</code></pre><p>Evaluate a binary tree (equation) over a given input data matrix. The operators contain all of the operators used. This function fuses doublets and triplets of operations for lower memory usage.</p><p><strong>Arguments</strong></p><ul><li><code>tree::AbstractExpressionNode</code>: The root node of the tree to evaluate.</li><li><code>cX::AbstractMatrix{T}</code>: The input data to evaluate the tree on, with shape <code>[num_features, num_rows]</code>.</li><li><code>operators::OperatorEnum</code>: The operators used in the tree.</li><li><code>eval_options::Union{EvalOptions,Nothing}</code>: See <a href="#DynamicExpressions.EvaluateModule.EvalOptions"><code>EvalOptions</code></a> for documentation   on the different evaluation modes.</li></ul><p><strong>Returns</strong></p><ul><li><code>(output, complete)::Tuple{AbstractVector{T}, Bool}</code>: the result,   which is a 1D array, as well as if the evaluation completed   successfully (true/false). A <code>false</code> complete means an infinity   or nan was encountered, and a large loss should be assigned   to the equation.</li></ul><p><strong>Notes</strong></p><p>This function can be represented by the following pseudocode:</p><pre><code class="nohighlight hljs">def eval(current_node)
    if current_node is leaf
        return current_node.value
    elif current_node is degree 1
        return current_node.operator(eval(current_node.left_child))
    else
        return current_node.operator(eval(current_node.left_child), eval(current_node.right_child))</code></pre><p>The bulk of the code is for optimizations and pre-emptive NaN/Inf checks, which speed up evaluation significantly.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SymbolicML/DynamicExpressions.jl/blob/7e0a1b459a80c07b6f384462f4aa1d9d751dea5c/src/Evaluate.jl#L89-L130">source</a></section></article><p>You can also use the following shorthand by using the expression as a function:</p><pre><code class="nohighlight hljs">    (tree::AbstractExpressionNode)(X, operators::OperatorEnum; kws...)

Evaluate a binary tree (equation) over a given input data matrix. The
operators contain all of the operators used. This function fuses doublets
and triplets of operations for lower memory usage.

# Arguments
- `tree::AbstractExpressionNode`: The root node of the tree to evaluate.
- `cX::AbstractMatrix{T}`: The input data to evaluate the tree on.
- `operators::OperatorEnum`: The operators used in the tree.
- `kws...`: Passed to [`eval_tree_array`](@ref).

# Returns
- `output::AbstractVector{T}`: the result, which is a 1D array.
    Any NaN, Inf, or other failure during the evaluation will result in the entire
    output array being set to NaN.</code></pre><p>For example,</p><pre><code class="language-julia hljs">using DynamicExpressions

operators = OperatorEnum(; binary_operators=[+, -, *], unary_operators=[cos])
tree = Node(; feature=1) * cos(Node(; feature=2) - 3.2)

tree([1 2 3; 4 5 6.], operators)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">3-element Vector{Float64}:
  0.6967067435533686
 -0.4544040965128262
 -2.8266669740855317</code></pre><p>This is possible because when you call <code>OperatorEnum</code>, it automatically re-defines <code>(::Node)(X)</code> to call the evaluation operation with the given <code>operators loaded. It also re-defines</code>print<code>,</code>show<code>, and the various operators, to work with the</code>Node` type.</p><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"><p>The <code>Node</code> type does not know about which <code>OperatorEnum</code> you used to create it. Thus, if you define an expression with one <code>OperatorEnum</code>, and then try to evaluate it or print it with a different <code>OperatorEnum</code>, you will get undefined behavior!</p><p>For safer behavior, you should use <a href="../api/#DynamicExpressions.ExpressionModule.Expression"><code>Expression</code></a> objects.</p></div></div><p>Evaluation options are specified using <code>EvalOptions</code>:</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="DynamicExpressions.EvaluateModule.EvalOptions" href="#DynamicExpressions.EvaluateModule.EvalOptions"><code>DynamicExpressions.EvaluateModule.EvalOptions</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">EvalOptions{T,B,E}</code></pre><p>This holds options for expression evaluation, such as evaluation backend.</p><p><strong>Fields</strong></p><ul><li><code>turbo::Val{T}=Val(false)</code>: If <code>Val{true}</code>, use LoopVectorization.jl for faster   evaluation.</li><li><code>bumper::Val{B}=Val(false)</code>: If <code>Val{true}</code>, use Bumper.jl for faster evaluation.</li><li><code>early_exit::Val{E}=Val(true)</code>: If <code>Val{true}</code>, any element of any step becoming   <code>NaN</code> or <code>Inf</code> will terminate the computation. For <code>eval_tree_array</code>, this will   result in the second return value, the completion flag, being <code>false</code>. For    calling an expression using <code>tree(X)</code>, this will result in <code>NaN</code>s filling   the entire buffer. This early exit is performed to avoid wasting compute cycles.   Setting <code>Val{false}</code> will continue the computation as usual and thus result in   <code>NaN</code>s only in the elements that actually have <code>NaN</code>s.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SymbolicML/DynamicExpressions.jl/blob/7e0a1b459a80c07b6f384462f4aa1d9d751dea5c/src/Evaluate.jl#L31-L48">source</a></section></article><p>You can also work with arbitrary types, by defining a <code>GenericOperatorEnum</code> instead. The notation is the same for <code>eval_tree_array</code>, though it will return <code>nothing</code> when it can&#39;t find a method, and not do any NaN checks:</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="DynamicExpressions.EvaluateModule.eval_tree_array-Tuple{Node, AbstractMatrix, GenericOperatorEnum}" href="#DynamicExpressions.EvaluateModule.eval_tree_array-Tuple{Node, AbstractMatrix, GenericOperatorEnum}"><code>DynamicExpressions.EvaluateModule.eval_tree_array</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">eval_tree_array(tree::AbstractExpressionNode, cX::AbstractMatrix, operators::GenericOperatorEnum; throw_errors::Bool=true)</code></pre><p>Evaluate a generic binary tree (equation) over a given input data, whatever that input data may be. The <code>operators</code> enum contains all of the operators used. Unlike <code>eval_tree_array</code> with the normal <code>OperatorEnum</code>, the array <code>cX</code> is sliced only along the first dimension. i.e., if <code>cX</code> is a vector, then the output of a feature node will be a scalar. If <code>cX</code> is a 3D tensor, then the output of a feature node will be a 2D tensor. Note also that <code>tree.feature</code> will index along the first axis of <code>cX</code>.</p><p>However, there is no requirement about input and output types in general. You may set up your tree such that some operator nodes work on tensors, while other operator nodes work on scalars. <code>eval_tree_array</code> will simply return <code>nothing</code> if a given operator is not defined for the given input type.</p><p>This function can be represented by the following pseudocode:</p><pre><code class="nohighlight hljs">function eval(current_node)
    if current_node is leaf
        return current_node.value
    elif current_node is degree 1
        return current_node.operator(eval(current_node.left_child))
    else
        return current_node.operator(eval(current_node.left_child), eval(current_node.right_child))</code></pre><p><strong>Arguments</strong></p><ul><li><code>tree::AbstractExpressionNode</code>: The root node of the tree to evaluate.</li><li><code>cX::AbstractArray</code>: The input data to evaluate the tree on.</li><li><code>operators::GenericOperatorEnum</code>: The operators used in the tree.</li><li><code>throw_errors::Bool=true</code>: Whether to throw errors   if they occur during evaluation. Otherwise,   MethodErrors will be caught before they happen and    evaluation will return <code>nothing</code>,   rather than throwing an error. This is useful in cases   where you are unsure if a particular tree is valid or not,   and would prefer to work with <code>nothing</code> as an output.</li></ul><p><strong>Returns</strong></p><ul><li><code>(output, complete)::Tuple{Any, Bool}</code>: the result,   as well as if the evaluation completed successfully (true/false).   If evaluation failed, <code>nothing</code> will be returned for the first argument.   A <code>false</code> complete means an operator was called on input types   that it was not defined for.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SymbolicML/DynamicExpressions.jl/blob/7e0a1b459a80c07b6f384462f4aa1d9d751dea5c/src/Evaluate.jl#L709-L756">source</a></section></article><p>Likewise for the shorthand notation:</p><pre><code class="nohighlight hljs">    (tree::Node)(X::AbstractMatrix, operators::GenericOperatorEnum; throw_errors::Bool=true)

# Arguments
- `X::AbstractArray`: The input data to evaluate the tree on.
- `operators::GenericOperatorEnum`: The operators used in the tree.
- `throw_errors::Bool=true`: Whether to throw errors
    if they occur during evaluation. Otherwise,
    MethodErrors will be caught before they happen and
    evaluation will return `nothing`,
    rather than throwing an error. This is useful in cases
    where you are unsure if a particular tree is valid or not,
    and would prefer to work with `nothing` as an output.

# Returns
- `output`: the result of the evaluation.
    If evaluation failed, `nothing` will be returned for the first argument.
    A `false` complete means an operator was called on input types
    that it was not defined for. You can change this behavior by
    setting `throw_errors=false`.</code></pre><h2 id="Derivatives"><a class="docs-heading-anchor" href="#Derivatives">Derivatives</a><a id="Derivatives-1"></a><a class="docs-heading-anchor-permalink" href="#Derivatives" title="Permalink"></a></h2><p><code>DynamicExpressions.jl</code> can efficiently compute first-order derivatives of expressions with respect to variables or constants. This is done using either <code>eval_diff_tree_array</code>, to compute derivative with respect to a single variable, or with <code>eval_grad_tree_array</code>, to compute the gradient with respect all variables (or, all constants). Both use forward-mode automatic, but use <code>Zygote.jl</code> to compute derivatives of each operator, so this is very efficient.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="DynamicExpressions.EvaluateDerivativeModule.eval_diff_tree_array-Union{Tuple{T}, Tuple{Node{T}, AbstractMatrix{T}, OperatorEnum, Integer}} where T&lt;:Number" href="#DynamicExpressions.EvaluateDerivativeModule.eval_diff_tree_array-Union{Tuple{T}, Tuple{Node{T}, AbstractMatrix{T}, OperatorEnum, Integer}} where T&lt;:Number"><code>DynamicExpressions.EvaluateDerivativeModule.eval_diff_tree_array</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">eval_diff_tree_array(
    tree::AbstractExpressionNode{T},
    cX::AbstractMatrix{T},
    operators::OperatorEnum,
    direction::Integer;
    turbo::Union{Bool,Val}=Val(false)
) where {T&lt;:Number}</code></pre><p>Compute the forward derivative of an expression, using a similar structure and optimization to eval<em>tree</em>array. <code>direction</code> is the index of a particular variable in the expression. e.g., <code>direction=1</code> would indicate derivative with respect to <code>x1</code>.</p><p><strong>Arguments</strong></p><ul><li><code>tree::AbstractExpressionNode</code>: The expression tree to evaluate.</li><li><code>cX::AbstractMatrix{T}</code>: The data matrix, with shape <code>[num_features, num_rows]</code>.</li><li><code>operators::OperatorEnum</code>: The operators used to create the <code>tree</code>.</li><li><code>direction::Integer</code>: The index of the variable to take the derivative with respect to.</li><li><code>turbo::Union{Bool,Val}</code>: Use LoopVectorization.jl for faster evaluation. Currently this does not have   any effect.</li></ul><p><strong>Returns</strong></p><ul><li><code>(evaluation, derivative, complete)::Tuple{AbstractVector{T}, AbstractVector{T}, Bool}</code>: the normal evaluation,   the derivative, and whether the evaluation completed as normal (or encountered a nan or inf).</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SymbolicML/DynamicExpressions.jl/blob/7e0a1b459a80c07b6f384462f4aa1d9d751dea5c/src/EvaluateDerivative.jl#L11-L38">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="DynamicExpressions.EvaluateDerivativeModule.eval_grad_tree_array-Union{Tuple{T}, Tuple{Node{T}, AbstractMatrix{T}, OperatorEnum}} where T&lt;:Number" href="#DynamicExpressions.EvaluateDerivativeModule.eval_grad_tree_array-Union{Tuple{T}, Tuple{Node{T}, AbstractMatrix{T}, OperatorEnum}} where T&lt;:Number"><code>DynamicExpressions.EvaluateDerivativeModule.eval_grad_tree_array</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">eval_grad_tree_array(tree::AbstractExpressionNode{T}, cX::AbstractMatrix{T}, operators::OperatorEnum; variable::Union{Bool,Val}=Val(false), turbo::Union{Bool,Val}=Val(false))</code></pre><p>Compute the forward-mode derivative of an expression, using a similar structure and optimization to eval<em>tree</em>array. <code>variable</code> specifies whether we should take derivatives with respect to features (i.e., cX), or with respect to every constant in the expression.</p><p><strong>Arguments</strong></p><ul><li><code>tree::AbstractExpressionNode{T}</code>: The expression tree to evaluate.</li><li><code>cX::AbstractMatrix{T}</code>: The data matrix, with each column being a data point.</li><li><code>operators::OperatorEnum</code>: The operators used to create the <code>tree</code>.</li><li><code>variable::Union{Bool,Val}</code>: Whether to take derivatives with respect to features (i.e., <code>cX</code> - with <code>variable=true</code>),   or with respect to every constant in the expression (<code>variable=false</code>).</li><li><code>turbo::Union{Bool,Val}</code>: Use LoopVectorization.jl for faster evaluation. Currently this does not have   any effect.</li></ul><p><strong>Returns</strong></p><ul><li><code>(evaluation, gradient, complete)::Tuple{AbstractVector{T}, AbstractMatrix{T}, Bool}</code>: the normal evaluation,   the gradient, and whether the evaluation completed as normal (or encountered a nan or inf).</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SymbolicML/DynamicExpressions.jl/blob/7e0a1b459a80c07b6f384462f4aa1d9d751dea5c/src/EvaluateDerivative.jl#L186-L208">source</a></section></article><p>You can compute gradients this with shorthand notation as well (which by default computes gradients with respect to input matrix, rather than constants).</p><pre><code class="nohighlight hljs">    (tree::Node{T})&#39;(X::AbstractMatrix{T}, operators::OperatorEnum; turbo::Bool=false, variable::Bool=true)

Compute the forward-mode derivative of an expression, using a similar
structure and optimization to eval_tree_array. `variable` specifies whether
we should take derivatives with respect to features (i.e., X), or with respect
to every constant in the expression.

# Arguments
- `X::AbstractMatrix{T}`: The data matrix, with each column being a data point.
- `operators::OperatorEnum`: The operators used to create the `tree`.
- `variable::Bool`: Whether to take derivatives with respect to features (i.e., `X` - with `variable=true`),
    or with respect to every constant in the expression (`variable=false`).
- `turbo::Bool`: Use `LoopVectorization.@turbo` for faster evaluation.

# Returns

- `(evaluation, gradient, complete)::Tuple{AbstractVector{T}, AbstractMatrix{T}, Bool}`: the normal evaluation,
    the gradient, and whether the evaluation completed as normal (or encountered a nan or inf).</code></pre><p>Alternatively, you can compute higher-order derivatives by using <code>ForwardDiff</code> on the function <code>differentiable_eval_tree_array</code>, although this will be slower.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="DynamicExpressions.EvaluateModule.differentiable_eval_tree_array-Union{Tuple{T}, Tuple{Node{T}, AbstractMatrix{T}, OperatorEnum}} where T&lt;:Number" href="#DynamicExpressions.EvaluateModule.differentiable_eval_tree_array-Union{Tuple{T}, Tuple{Node{T}, AbstractMatrix{T}, OperatorEnum}} where T&lt;:Number"><code>DynamicExpressions.EvaluateModule.differentiable_eval_tree_array</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">differentiable_eval_tree_array(tree::AbstractExpressionNode, cX::AbstractMatrix, operators::OperatorEnum)</code></pre><p>Evaluate an expression tree in a way that can be auto-differentiated.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SymbolicML/DynamicExpressions.jl/blob/7e0a1b459a80c07b6f384462f4aa1d9d751dea5c/src/Evaluate.jl#L647-L651">source</a></section></article><h3 id="Enzyme"><a class="docs-heading-anchor" href="#Enzyme">Enzyme</a><a id="Enzyme-1"></a><a class="docs-heading-anchor-permalink" href="#Enzyme" title="Permalink"></a></h3><p><code>DynamicExpressions.jl</code> also supports automatic differentiation with <a href="https://github.com/EnzymeAD/Enzyme.jl"><code>Enzyme.jl</code></a>. Note that this is <strong>extremely experimental</strong>. You should expect to see occasional incorrect gradients. Be sure to explicitly verify gradients are correct for a particular space of operators (e.g., with finite differences).</p><p>Let&#39;s look at an example. First, let&#39;s create a tree:</p><pre><code class="language-julia hljs">using DynamicExpressions

operators = OperatorEnum(binary_operators=(+, -, *, /), unary_operators=(cos, sin))

x1 = Node{Float64}(feature=1)
x2 = Node{Float64}(feature=2)

tree = 0.5 * x1 + cos(x2 - 0.2)</code></pre><p>Now, say we want to take the derivative of this expression with respect to x1 and x2. First, let&#39;s evaluate it normally:</p><pre><code class="language-julia hljs">X = [1.0 2.0 3.0; 4.0 5.0 6.0]  # 2x3 matrix (2 features, 3 rows)

tree(X, operators)</code></pre><p>Now, let&#39;s use <code>Enzyme.jl</code> to compute the derivative of the outputs with respect to x1 and x2, using reverse-mode autodiff:</p><pre><code class="language-julia hljs">using Enzyme

function my_loss_function(tree, X, operators)
    # Get the outputs
    y = tree(X, operators)
    # Sum them (so we can take a gradient, rather than a jacobian)
    return sum(y)
end


dX = begin
    storage=zero(X)
    autodiff(
        Reverse,
        my_loss_function,
        Active,
        ## Actual arguments to function:
        Const(tree),
        Duplicated(X, storage),
        Const(operators),
    )
    storage
end</code></pre><p>This will get returned as</p><pre><code class="language-text hljs"> 2×3 Matrix{Float64}:
  0.5       0.5       0.5
  0.611858  0.996165  0.464602</code></pre><p>which one can confirm is the correct gradient!</p><p>This will take a while the first time you run it, as Enzyme needs to take the gradients of the actual LLVM IR code. Subsequent runs won&#39;t spend any time compiling and be much faster.</p><p>Some general notes about this:</p><ol><li>We want to take a reverse-mode gradient, so we pass <code>Reverse</code> to <code>autodiff</code>.</li><li>Since we want to take the gradient of the <em>output</em> of <code>my_loss_function</code>, we declare <code>Active</code> as the third argument.</li><li>Following this, we pass our actual arguments to the function.<ul><li>Objects which we don&#39;t want to take gradients with respect to,  and also don&#39;t temporarily store any data during the computation  (such as <code>tree</code> and <code>operators</code> here) should be wrapped with <code>Const</code>.</li><li>Objects which we wish to take derivatives with respect to, we need to use   <code>Duplicated</code>, and explicitly create a copy of it, with all numerical values   set to zero. Enzyme will then store the derivatives in this object.</li></ul></li></ol><p>Note that you should never use anything other than <code>turbo=Val(false)</code> with Enzyme, as Enzyme and LoopVectorization are not compatible, and will cause a segfault. <em>Even using <code>turbo=false</code> will not work, because it would cause Enzyme to trace the (unused) LoopVectorization code!</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../examples/structured_expression/">« <code>StructuredExpression</code> example</a><a class="docs-footer-nextpage" href="../utils/">Utils »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.8.0 on <span class="colophon-date" title="Saturday 7 December 2024 19:30">Saturday 7 December 2024</span>. Using Julia version 1.11.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
